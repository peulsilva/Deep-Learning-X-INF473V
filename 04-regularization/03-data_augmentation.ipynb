{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data augmentation\n",
    "\n",
    "In real life, we often have to deal with a small dataset. In this case, we can use data augmentation to artificially increase the size of the dataset. For images multiple data augmentations techniques exist such as:\n",
    "- Cropping\n",
    "- Color Jittering\n",
    "- Geometric transformations\n",
    "- A lot other techniques (see `torchvision.Transforms` or `Albumentation`)\n",
    "\n",
    "### Question 6\n",
    "The main idea here is to \"create\" new data from existing datapoints.\n",
    "Create a lambda transform that jitters the datapoints with Gaussian noise.\n",
    "Use a dataset with 50 samples and train a classifier that leverage the augmentation with stds = [0, 1e-2, 1e-1, 2e-1, 1]. Make sure to have the same train dataset for each exp.\n",
    "Discuss the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomNoiseTransform(object):\n",
    "    def __init__(self, std=0.001):\n",
    "        ### YOUR CODE HERE\n",
    "\n",
    "noise_levels = [0, 1e-2, 1e-1, 2e-1, 1]\n",
    "num_noise_levels = len(noise_levels)\n",
    "train_losses = {}\n",
    "val_losses = {}\n",
    "train_accs = {}\n",
    "val_accs = {}\n",
    "test_accs = {}\n",
    "\n",
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 7\n",
    "Visualize the augmented training set for the noise level that gave the best test accuracy. Plot the original points in one color and the augmented one in another. To be able to visualize well what's happening, display 100 iterations on the augmented dataset. What conclusion can you draw from this observation. Could you think of a \"smarter\" way to augment the data if you can make assumption on the structure of the data manifold?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 8\n",
    "Another way to regularize the training is to use dropout. Implement the dropout operation as an nn.Module. Remember, dropout is only implemented when training. Fortunally, `torch.nn.Module` has a flag `training` which is true if the model is training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dropout(nn.Module):\n",
    "   ### YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 9\n",
    "Use dropout to train a model on the circle dataset with 100 samples. Use the same architecture as in Question 8. train with different values of dropout and plot the training and validation loss and accuracy. Compute the test accuracy. What can you conclude?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dropout(dropout_rate, train_loader, val_loader, test_loader, device, epochs=1000):\n",
    "    ### YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
